{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c54d5436-a103-4743-8731-13e8510a2d94",
      "metadata": {
        "id": "c54d5436-a103-4743-8731-13e8510a2d94"
      },
      "source": [
        "## Homework 9: Text Classification with Fine-Tuned BERT\n",
        "\n",
        "### Due: Midnight on November 5th (with 2-hour grace period) — Worth 85 points\n",
        "\n",
        "In this final homework, we’ll explore **fine-tuning a pre-trained Transformer model (BERT)** for text classification using the **IMDB Movie Review** dataset. You’ll begin with a working baseline notebook and then conduct a series of controlled experiments to understand how data size, context length, and model architecture affect performance.\n",
        "\n",
        "You’ll complete three problems:\n",
        "\n",
        "* **Problem 1:** Evaluate how **sequence length** and **learning rate** jointly influence validation loss and generalization.\n",
        "* **Problem 2:** Measure how **training data size** affects both model performance and total training time.\n",
        "* **Problem 3:** Compare **two additional models** from the BERT family to analyze the trade-offs between model size and accuracy on this dataset.\n",
        "\n",
        "In each problem, you’ll report your key metrics, summarize what you observed, and reflect on what you learned.\n",
        "\n",
        "> **Note:** This homework was developed and tested on **Google Colab**, due to version conflicts when running locally. It is **strongly recommended** that you complete your work on Colab as well.\n",
        "\n",
        "There are 6 problems, each worth 14 points, and you get one point free if you complete the entire homework.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "S-zVZFxlTWxP",
      "metadata": {
        "id": "S-zVZFxlTWxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ade42e12-8957-4a15-c5bf-6c38a933377f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m80.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m645.0/645.0 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "keras-nlp 0.21.1 requires keras-hub==0.21.1, but you have keras-hub 0.23.0 which is incompatible.\n",
            "tensorflow-decision-forests 1.12.0 requires tensorflow==2.19.0, but you have tensorflow 2.19.1 which is incompatible.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# Install once per new Colab runtime\n",
        "%pip -q install -U keras keras-hub tensorflow tensorflow-text datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "bb6035ef-078b-4ae3-8695-7e0d135cd51e",
      "metadata": {
        "id": "bb6035ef-078b-4ae3-8695-7e0d135cd51e"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import keras\n",
        "import keras_hub as kh\n",
        "import evaluate\n",
        "from datasets import load_dataset, Dataset, Features, Value, ClassLabel\n",
        "\n",
        "from keras import mixed_precision                    # generally faster\n",
        "mixed_precision.set_global_policy(\"mixed_float16\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50a9307f-eb34-49e7-84e8-ed373dbd8ef3",
      "metadata": {
        "id": "50a9307f-eb34-49e7-84e8-ed373dbd8ef3"
      },
      "source": [
        "### Here is where you can set global hyperparameters for this homework"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "189c9bbc-c634-417f-909b-ccc4d5945c76",
      "metadata": {
        "id": "189c9bbc-c634-417f-909b-ccc4d5945c76"
      },
      "outputs": [],
      "source": [
        "# ---------------- Config ----------------\n",
        "SEED        = 42\n",
        "MAX_LEN     = 128\n",
        "EPOCHS      = 3\n",
        "BATCH       = 32\n",
        "EVAL_BATCH  = 64\n",
        "SUBSET_FRAC = 1.0   # <-- 0.25 to train and test on 25% of whole dataset during development;  set to 1.0 for full dataset\n",
        "\n",
        "keras.utils.set_random_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d33d68ff-94e2-402a-8bd3-fef3cba9e7bf",
      "metadata": {
        "id": "d33d68ff-94e2-402a-8bd3-fef3cba9e7bf"
      },
      "source": [
        "### Load and Preprocess the IMDB Movie Review Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "59c3b6bd-ddc3-4c75-b0ba-8b09d2f42a96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59c3b6bd-ddc3-4c75-b0ba-8b09d2f42a96",
        "outputId": "eb38efba-9a74-4c89-af65-a983e6b4b3b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool after SUBSET_FRAC=1.0: 50000 (of 50000)\n",
            "Train: (35000, [17500, 17500])  Val: (5000, [2500, 2500])  Test: (10000, [5000, 5000])\n"
          ]
        }
      ],
      "source": [
        "# ---- Load IMDb (raw), join train+test ----\n",
        "imdb   = load_dataset(\"imdb\")\n",
        "texts  = list(imdb[\"train\"][\"text\"]) + list(imdb[\"test\"][\"text\"])\n",
        "labels = np.array(list(imdb[\"train\"][\"label\"]) + list(imdb[\"test\"][\"label\"]), dtype=\"int32\")\n",
        "\n",
        "# ---- Build DS with explicit features (label=ClassLabel) ----\n",
        "features = Features({\"text\": Value(\"string\"),\n",
        "                     \"label\": ClassLabel(num_classes=2, names=[\"NEG\",\"POS\"])})\n",
        "all_ds = Dataset.from_dict({\"text\": texts, \"label\": labels.tolist()}, features=features)\n",
        "\n",
        "# ---- Optional: take a stratified subset of the FULL dataset ----\n",
        "if 0.0 < SUBSET_FRAC < 1.0:\n",
        "    sub = all_ds.train_test_split(train_size=SUBSET_FRAC, seed=SEED, stratify_by_column=\"label\")\n",
        "    ds_pool = sub[\"train\"]\n",
        "else:\n",
        "    ds_pool = all_ds\n",
        "\n",
        "# ---- Stratified 80/10/10 split on the (possibly smaller) pool ----\n",
        "# First: 80/20 train+val pool / test\n",
        "splits = ds_pool.train_test_split(test_size=0.20, seed=SEED, stratify_by_column=\"label\")\n",
        "train_val_pool, test_ds = splits[\"train\"], splits[\"test\"]\n",
        "# Then: carve 10% of full (i.e., 0.125 of the 80% pool) as validation\n",
        "splits2 = train_val_pool.train_test_split(test_size=0.125, seed=SEED, stratify_by_column=\"label\")\n",
        "train_ds, val_ds = splits2[\"train\"], splits2[\"test\"]\n",
        "\n",
        "# ---- Numpy arrays for Keras fit/predict ----\n",
        "X_tr = np.array(train_ds[\"text\"], dtype=object); y_tr = np.array(train_ds[\"label\"], dtype=\"int32\")\n",
        "X_va = np.array(val_ds[\"text\"],   dtype=object); y_va = np.array(val_ds[\"label\"],   dtype=\"int32\")\n",
        "X_te = np.array(test_ds[\"text\"],  dtype=object); y_te = np.array(test_ds[\"label\"],  dtype=\"int32\")\n",
        "\n",
        "# ---- Quick summary ----\n",
        "def _counts(ds):\n",
        "    arr = np.array(ds[\"label\"], dtype=int)\n",
        "    return len(arr), np.bincount(arr, minlength=2).tolist()\n",
        "print(f\"Pool after SUBSET_FRAC={SUBSET_FRAC}: {len(ds_pool)} (of {len(all_ds)})\")\n",
        "print(\"Train:\", _counts(train_ds), \" Val:\", _counts(val_ds), \" Test:\", _counts(test_ds))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c6e3cf44-614f-4b4b-801a-8865adf1ded3",
      "metadata": {
        "id": "c6e3cf44-614f-4b4b-801a-8865adf1ded3"
      },
      "source": [
        "### Build and train a baseline Distil-Bert Text Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "4814b089-9299-4828-865a-81ae45bb2bb5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517,
          "referenced_widgets": [
            "15dbe12a761e4e70a51e20770003fc1f",
            "0eabf0f7428f4a319d8ef84fdb4d8ca5",
            "47b2f287487d48d295650dde5ae9861d",
            "1bc00639181b4d23b0ef928094385bda",
            "1b499c0665d543bb88ea7cb57fece253",
            "dca0b379100741dc846e017a5d614c76",
            "74c3219ccdd94e0ab1713f6e3ff301ff",
            "8ea50da1c49647a8a06ce8232d0521e7",
            "bd65acdaa6064ee8a6f27ad2d57f9ef1",
            "4926984e46164c0d83ed2e3a0caffc47",
            "aae4943ef9e54eabbc6c0d6d7cc39831",
            "c0283cc0c54c4225ab06448e789db75d",
            "34d7059fe01a4a92a3d54b601ba897c3",
            "40e31ae2250a4e388285b59d229489dd",
            "bd8c60b8d74848bebe39458acb5e37ca",
            "49aaf1aa3e384c38b239fdd6f50ae46e",
            "0d50d1e7173c49fa8c7a4e0db08a42e4",
            "275a90afc6064a4dadedd928e9663749",
            "c250c46f87e44f4cb265da7edc38d42c",
            "9d56cb52532a4c318b63e6657c66fd9c",
            "c9f963be16574379aa7d828635b5a66b",
            "a98d4e503d254967b96a4c8bbb7cba5b"
          ]
        },
        "id": "4814b089-9299-4828-865a-81ae45bb2bb5",
        "outputId": "c6e4ff9e-6ff9-49fc-f077-02672b080bf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/distil_bert/keras/distil_bert_base_en_uncased/3/download/config.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 462/462 [00:00<00:00, 1.08MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/distil_bert/keras/distil_bert_base_en_uncased/3/download/tokenizer.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 794/794 [00:00<00:00, 1.81MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/distil_bert/keras/distil_bert_base_en_uncased/3/download/assets/tokenizer/vocabulary.txt...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 226k/226k [00:00<00:00, 265kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/distil_bert/keras/distil_bert_base_en_uncased/3/download/model.weights.h5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 253M/253M [00:17<00:00, 15.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 242ms/step - acc: 0.7822 - loss: 0.4529 - val_acc: 0.8376 - val_loss: 0.3449\n",
            "Epoch 2/3\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 34ms/step - acc: 0.8779 - loss: 0.2901 - val_acc: 0.8592 - val_loss: 0.3396\n",
            "Epoch 3/3\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 33ms/step - acc: 0.9153 - loss: 0.2209 - val_acc: 0.8608 - val_loss: 0.3552\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15dbe12a761e4e70a51e20770003fc1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0283cc0c54c4225ab06448e789db75d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation acc (best epoch): 0.859\n",
            "\n",
            "Test accuracy: 0.855   Test F1: 0.851\n",
            "\n",
            "Confusion matrix:\n",
            " [[1098  152]\n",
            " [ 211 1039]]\n",
            "\n",
            "Elapsed time: 00:02:47\n"
          ]
        }
      ],
      "source": [
        "# ---- Keras Hub preprocessor + classifier ----\n",
        "preproc = kh.models.DistilBertTextClassifierPreprocessor.from_preset(\n",
        "    \"distil_bert_base_en_uncased\", sequence_length=MAX_LEN\n",
        ")\n",
        "model = kh.models.DistilBertTextClassifier.from_preset(\n",
        "    \"distil_bert_base_en_uncased\", num_classes=2, preprocessor=preproc\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(1e-5),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "# ---- Train with early stopping (restore best val weights) ----\n",
        "cb = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True)]\n",
        "history = model.fit(\n",
        "    X_tr, y_tr,\n",
        "    validation_data=(X_va, y_va),\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH,\n",
        "    callbacks=cb,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# ---- Evaluate (accuracy + F1 via `evaluate`) ----\n",
        "logits = model.predict(X_te, batch_size=EVAL_BATCH, verbose=0)\n",
        "y_pred = logits.argmax(axis=-1)\n",
        "\n",
        "acc_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric  = evaluate.load(\"f1\")\n",
        "acc = acc_metric.compute(predictions=y_pred, references=y_te)[\"accuracy\"]\n",
        "f1  = f1_metric.compute(predictions=y_pred, references=y_te)[\"f1\"]\n",
        "\n",
        "# Tiny confusion matrix helper (no sklearn needed)\n",
        "def confusion_matrix_np(y_true, y_pred, num_classes=2):\n",
        "    cm = np.zeros((num_classes, num_classes), dtype=int)\n",
        "    for t, p in zip(y_true, y_pred):\n",
        "        cm[t, p] += 1\n",
        "    return cm\n",
        "\n",
        "print(f\"\\nValidation acc (best epoch): {history.history['val_acc'][np.argmin(history.history['val_loss'])]:.3f}\")\n",
        "print(f\"\\nTest accuracy: {acc:.3f}   Test F1: {f1:.3f}\")\n",
        "print(\"\\nConfusion matrix:\\n\", confusion_matrix_np(y_te, y_pred))\n",
        "\n",
        "end = time.time() - start\n",
        "print(\"\\nElapsed time:\", time.strftime(\"%H:%M:%S\", time.gmtime(end)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2fe4979-adac-4d73-aa57-a91cd0b2ad34",
      "metadata": {
        "id": "d2fe4979-adac-4d73-aa57-a91cd0b2ad34"
      },
      "source": [
        "# Problem 1 — Mini sweep: context length × learning rate (6 runs)\n",
        "\n",
        "In this problem we'll see how much **context length** (`MAX_LEN`) helps, and how sensitive fine-tuning is to **learning rate**—without running a huge grid.\n",
        "\n",
        "## Setup (keep these fixed)\n",
        "\n",
        "* `SUBSET_FRAC = 0.25`               # use only this percentage of the whole dataset\n",
        "* `EPOCHS = 3`\n",
        "* `BATCH = 32` (but see note for 256 below)\n",
        "* **EarlyStopping** with `restore_best_weights=True`\n",
        "* Same random `SEED` for all runs\n",
        "* Same data split for all runs (don’t reshuffle between runs)\n",
        "\n",
        "### Run these 6 configurations\n",
        "\n",
        "**For each** `MAX_LEN ∈ {128, 256, 512}`, try **two** learning rates:\n",
        "\n",
        "* **MAX_LEN = 128**\n",
        "\n",
        "  * `(LR = 2e-5, BATCH = 32)` – healthy default for shorter contexts.\n",
        "  * `(LR = 1e-5, BATCH = 32)` – conservative LR; often a touch stabler.\n",
        "\n",
        "* **MAX_LEN = 256**\n",
        "\n",
        "  * `(LR = 1e-5, BATCH = 16)` – longer context → lower batch.\n",
        "  * `(LR = 7.5e-6, BATCH = 16)` – even steadier if loss is noisy.\n",
        "\n",
        "* **MAX_LEN = 512**  *(heavier quadratic attention cost)*\n",
        "\n",
        "  * `(LR = 7.5e-6, BATCH = 8)` – safe starting point.\n",
        "  * `(LR = 5e-6, BATCH = 8)` – extra caution for stability.\n",
        "\n",
        "**If you hit an Out Of Memory error:**\n",
        "\n",
        "* At **256** with `BATCH = 16`, drop to `BATCH = 8`.\n",
        "* At **512** with `BATCH = 8`, drop to `BATCH = 4`.\n",
        "\n",
        "\n",
        "Then answer the graded questions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "bd105932-3dc1-47e5-9b4a-90f4e9206143",
      "metadata": {
        "id": "bd105932-3dc1-47e5-9b4a-90f4e9206143",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71802c24-b20d-431b-edb5-789c09829f5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Bert model with Max Sequance length: 128, Learning Rate: 2e-05, and Batch Size 32 ...\n",
            "Epoch 1/3\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 162ms/step - acc: 0.8054 - loss: 0.4123 - val_acc: 0.8512 - val_loss: 0.3367\n",
            "Epoch 2/3\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - acc: 0.9013 - loss: 0.2497 - val_acc: 0.8440 - val_loss: 0.3884\n",
            "Epoch 3/3\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - acc: 0.9358 - loss: 0.1734 - val_acc: 0.8520 - val_loss: 0.3729\n",
            "Running Bert model with Max Sequance length: 128, Learning Rate: 2e-05, and Batch Size 32 ...\n",
            "\n",
            "Validation acc (best epoch): 0.851\n",
            "\n",
            "Test accuracy: 0.851   Test F1: 0.855\n",
            "\n",
            "Confusion matrix:\n",
            " [[1035  215]\n",
            " [ 157 1093]]\n",
            "\n",
            "Elapsed time: 00:02:00\n",
            "Running Bert model with Max Sequance length: 128, Learning Rate: 1e-05, and Batch Size 32 ...\n",
            "Epoch 1/3\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 159ms/step - acc: 0.7845 - loss: 0.4510 - val_acc: 0.8536 - val_loss: 0.3467\n",
            "Epoch 2/3\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 36ms/step - acc: 0.8810 - loss: 0.2903 - val_acc: 0.8600 - val_loss: 0.3450\n",
            "Epoch 3/3\n",
            "\u001b[1m274/274\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 35ms/step - acc: 0.9126 - loss: 0.2233 - val_acc: 0.8568 - val_loss: 0.3589\n",
            "Running Bert model with Max Sequance length: 128, Learning Rate: 1e-05, and Batch Size 32 ...\n",
            "\n",
            "Validation acc (best epoch): 0.860\n",
            "\n",
            "Test accuracy: 0.850   Test F1: 0.853\n",
            "\n",
            "Confusion matrix:\n",
            " [[1039  211]\n",
            " [ 164 1086]]\n",
            "\n",
            "Elapsed time: 00:02:00\n",
            "Running Bert model with Max Sequance length: 256, Learning Rate: 1e-05, and Batch Size 16 ...\n",
            "Epoch 1/3\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 95ms/step - acc: 0.8014 - loss: 0.4122 - val_acc: 0.8520 - val_loss: 0.3439\n",
            "Epoch 2/3\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - acc: 0.8960 - loss: 0.2607 - val_acc: 0.8480 - val_loss: 0.3773\n",
            "Epoch 3/3\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 24ms/step - acc: 0.9306 - loss: 0.1901 - val_acc: 0.8496 - val_loss: 0.3971\n",
            "Running Bert model with Max Sequance length: 256, Learning Rate: 1e-05, and Batch Size 16 ...\n",
            "\n",
            "Validation acc (best epoch): 0.852\n",
            "\n",
            "Test accuracy: 0.846   Test F1: 0.847\n",
            "\n",
            "Confusion matrix:\n",
            " [[1057  193]\n",
            " [ 191 1059]]\n",
            "\n",
            "Elapsed time: 00:02:25\n",
            "Running Bert model with Max Sequance length: 256, Learning Rate: 7.5e-06, and Batch Size 16 ...\n",
            "Epoch 1/3\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 86ms/step - acc: 0.7936 - loss: 0.4367 - val_acc: 0.8560 - val_loss: 0.3399\n",
            "Epoch 2/3\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 21ms/step - acc: 0.8809 - loss: 0.2848 - val_acc: 0.8680 - val_loss: 0.3310\n",
            "Epoch 3/3\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - acc: 0.9190 - loss: 0.2101 - val_acc: 0.8640 - val_loss: 0.3522\n",
            "Running Bert model with Max Sequance length: 256, Learning Rate: 7.5e-06, and Batch Size 16 ...\n",
            "\n",
            "Validation acc (best epoch): 0.868\n",
            "\n",
            "Test accuracy: 0.852   Test F1: 0.855\n",
            "\n",
            "Confusion matrix:\n",
            " [[1036  214]\n",
            " [ 156 1094]]\n",
            "\n",
            "Elapsed time: 00:02:07\n",
            "Running Bert model with Max Sequance length: 512, Learning Rate: 7.5e-06, and Batch Size 8 ...\n",
            "Epoch 1/3\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 61ms/step - acc: 0.8046 - loss: 0.4102 - val_acc: 0.8520 - val_loss: 0.3511\n",
            "Epoch 2/3\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - acc: 0.8937 - loss: 0.2628 - val_acc: 0.8472 - val_loss: 0.3742\n",
            "Epoch 3/3\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 15ms/step - acc: 0.9280 - loss: 0.1881 - val_acc: 0.8624 - val_loss: 0.4083\n",
            "Running Bert model with Max Sequance length: 512, Learning Rate: 7.5e-06, and Batch Size 8 ...\n",
            "\n",
            "Validation acc (best epoch): 0.852\n",
            "\n",
            "Test accuracy: 0.850   Test F1: 0.856\n",
            "\n",
            "Confusion matrix:\n",
            " [[1011  239]\n",
            " [ 136 1114]]\n",
            "\n",
            "Elapsed time: 00:02:50\n",
            "Running Bert model with Max Sequance length: 512, Learning Rate: 5e-06, and Batch Size 8 ...\n",
            "Epoch 1/3\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 46ms/step - acc: 0.7926 - loss: 0.4330 - val_acc: 0.8440 - val_loss: 0.3465\n",
            "Epoch 2/3\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - acc: 0.8814 - loss: 0.2892 - val_acc: 0.8568 - val_loss: 0.3445\n",
            "Epoch 3/3\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 15ms/step - acc: 0.9135 - loss: 0.2192 - val_acc: 0.8656 - val_loss: 0.3622\n",
            "Running Bert model with Max Sequance length: 512, Learning Rate: 5e-06, and Batch Size 8 ...\n",
            "\n",
            "Validation acc (best epoch): 0.857\n",
            "\n",
            "Test accuracy: 0.857   Test F1: 0.859\n",
            "\n",
            "Confusion matrix:\n",
            " [[1049  201]\n",
            " [ 157 1093]]\n",
            "\n",
            "Elapsed time: 00:02:20\n"
          ]
        }
      ],
      "source": [
        "# Your code here; add as many cells as you need\n",
        "max_len_dict = {\n",
        "    '128':[[128, 2e-5, 32],[128, 1e-5, 32]],\n",
        "    '256':[[256, 1e-5, 16],[256, 7.5e-6, 16]],\n",
        "    '512':[[512, 7.5e-6, 8],[512, 5e-6, 8]]\n",
        "}\n",
        "\n",
        "for i in max_len_dict.keys():\n",
        "  for j in max_len_dict[i]:\n",
        "    print(f\"Running Bert model with Max Sequance length: {j[0]}, Learning Rate: {j[1]}, and Batch Size {j[2]} ...\")\n",
        "\n",
        "    preproc = kh.models.DistilBertTextClassifierPreprocessor.from_preset(\n",
        "        \"distil_bert_base_en_uncased\", sequence_length=j[0]\n",
        "    )\n",
        "    model = kh.models.DistilBertTextClassifier.from_preset(\n",
        "        \"distil_bert_base_en_uncased\", num_classes=2, preprocessor=preproc\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(j[1]),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
        "    )\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # ---- Train with early stopping (restore best val weights) ----\n",
        "    cb = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True)]\n",
        "    history = model.fit(\n",
        "        X_tr, y_tr,\n",
        "        validation_data=(X_va, y_va),\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=j[2],\n",
        "        callbacks=cb,\n",
        "        verbose=1,\n",
        "    )\n",
        "\n",
        "    # ---- Evaluate (accuracy + F1 via `evaluate`) ----\n",
        "    logits = model.predict(X_te, batch_size=EVAL_BATCH, verbose=0)\n",
        "    y_pred = logits.argmax(axis=-1)\n",
        "\n",
        "    acc_metric = evaluate.load(\"accuracy\")\n",
        "    f1_metric  = evaluate.load(\"f1\")\n",
        "    acc = acc_metric.compute(predictions=y_pred, references=y_te)[\"accuracy\"]\n",
        "    f1  = f1_metric.compute(predictions=y_pred, references=y_te)[\"f1\"]\n",
        "\n",
        "    # ---- Print the evaluations ----\n",
        "    print(f\"Running Bert model with Max Sequance length: {j[0]}, Learning Rate: {j[1]}, and Batch Size {j[2]} ...\")\n",
        "    print(f\"\\nValidation acc (best epoch): {history.history['val_acc'][np.argmin(history.history['val_loss'])]:.3f}\")\n",
        "    print(f\"\\nTest accuracy: {acc:.3f}   Test F1: {f1:.3f}\")\n",
        "    print(\"\\nConfusion matrix:\\n\", confusion_matrix_np(y_te, y_pred))\n",
        "\n",
        "    end = time.time() - start\n",
        "    print(\"\\nElapsed time:\", time.strftime(\"%H:%M:%S\", time.gmtime(end)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1aa6ea8a-6482-4c7b-81ba-aadbb3bfe564",
      "metadata": {
        "id": "1aa6ea8a-6482-4c7b-81ba-aadbb3bfe564"
      },
      "source": [
        "### Graded Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "a67d26c5-8294-438a-b29f-6a091180a1f8",
      "metadata": {
        "id": "a67d26c5-8294-438a-b29f-6a091180a1f8"
      },
      "outputs": [],
      "source": [
        "# Set a1a to the validation accuracy at min validation loss for your best configuration found in this problem\n",
        "\n",
        "a1a = 0.868          # Replace 0.0 with your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "0dd1c33c-4761-4954-a04d-e4e4def945ab",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dd1c33c-4761-4954-a04d-e4e4def945ab",
        "outputId": "05ce7d9a-b831-4f43-c6f5-e04ff7a318c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a1a = 0.8680\n"
          ]
        }
      ],
      "source": [
        "# Graded Answer\n",
        "# DO NOT change this cell in any way\n",
        "\n",
        "print(f'a1a = {a1a:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d46d2a89-301d-4f8d-9236-f88a1bc023ca",
      "metadata": {
        "id": "d46d2a89-301d-4f8d-9236-f88a1bc023ca"
      },
      "source": [
        "#### Question a1b:\n",
        "\n",
        "* Does **more context** (128 → 256 → 512) consistently help?\n",
        "* How much effect did the learning rate have on the validation accuracy?\n",
        "\n",
        "\n",
        "#### Your Answer Here: In general the higher context models performed better but it wasn't by a large margin. The learning rates impacted the models but not in a consistent manner, the combination of sequance length and learning rate may have hit an optimal low for one of the variants but performed moderately with a different combination."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6ef49299-6f39-4b66-9e16-52417f3f917f",
      "metadata": {
        "id": "6ef49299-6f39-4b66-9e16-52417f3f917f"
      },
      "source": [
        "## Problem 2 — How much data is enough?\n",
        "\n",
        "In this problem, you’ll investigate how model performance scales with dataset size.\n",
        "\n",
        "**Setup.**\n",
        "Use the best `MAX_LEN` and `LR` values you found in **Problem 1**.\n",
        "\n",
        "**What to do:**\n",
        "\n",
        "1. For each value of `SUBSET_FRAC ∈ {0.25, 0.50, 0.75, 1.00}`, train your model once and observe the displayed performance metrics.\n",
        "2. Answer the discussion question below.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "82b9ebc5-809a-4e13-a4c6-1325b0d9a171",
      "metadata": {
        "id": "82b9ebc5-809a-4e13-a4c6-1325b0d9a171",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96d25a5d-7e87-4bcb-fe54-678cc69e329a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Creating new datasetset of size 0.25\n",
            "Pool after SUBSET_FRAC=0.25: 12500 (of 50000)\n",
            "Train: (8750, [4375, 4375])  Val: (1250, [625, 625])  Test: (2500, [1250, 1250])\n",
            "\n",
            "\n",
            "Running Bert model with data subset size 0.25\n",
            "Epoch 1/3\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 83ms/step - acc: 0.7887 - loss: 0.4386 - val_acc: 0.8368 - val_loss: 0.3648\n",
            "Epoch 2/3\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 20ms/step - acc: 0.8813 - loss: 0.2866 - val_acc: 0.8440 - val_loss: 0.3790\n",
            "Epoch 3/3\n",
            "\u001b[1m547/547\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - acc: 0.9150 - loss: 0.2161 - val_acc: 0.8504 - val_loss: 0.4062\n",
            "\n",
            "Validation acc (best epoch): 0.837\n",
            "\n",
            "Test accuracy: 0.845   Test F1: 0.852\n",
            "\n",
            "Confusion matrix:\n",
            " [[ 998  252]\n",
            " [ 135 1115]]\n",
            "\n",
            "Elapsed time: 00:02:07\n",
            "\n",
            "\n",
            "Creating new datasetset of size 0.5\n",
            "Pool after SUBSET_FRAC=0.5: 25000 (of 50000)\n",
            "Train: (17500, [8750, 8750])  Val: (2500, [1250, 1250])  Test: (5000, [2500, 2500])\n",
            "\n",
            "\n",
            "Running Bert model with data subset size 0.5\n",
            "Epoch 1/3\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 48ms/step - acc: 0.8260 - loss: 0.3844 - val_acc: 0.8628 - val_loss: 0.3091\n",
            "Epoch 2/3\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 19ms/step - acc: 0.8862 - loss: 0.2736 - val_acc: 0.8692 - val_loss: 0.3099\n",
            "Epoch 3/3\n",
            "\u001b[1m1094/1094\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - acc: 0.9165 - loss: 0.2136 - val_acc: 0.8748 - val_loss: 0.3127\n",
            "\n",
            "Validation acc (best epoch): 0.863\n",
            "\n",
            "Test accuracy: 0.870   Test F1: 0.871\n",
            "\n",
            "Confusion matrix:\n",
            " [[2143  357]\n",
            " [ 294 2206]]\n",
            "\n",
            "Elapsed time: 00:02:33\n",
            "\n",
            "\n",
            "Creating new datasetset of size 0.75\n",
            "Pool after SUBSET_FRAC=0.75: 37500 (of 50000)\n",
            "Train: (26250, [13125, 13125])  Val: (3750, [1875, 1875])  Test: (7500, [3750, 3750])\n",
            "\n",
            "\n",
            "Running Bert model with data subset size 0.75\n",
            "Epoch 1/3\n",
            "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 38ms/step - acc: 0.8341 - loss: 0.3694 - val_acc: 0.8699 - val_loss: 0.3046\n",
            "Epoch 2/3\n",
            "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - acc: 0.8923 - loss: 0.2628 - val_acc: 0.8752 - val_loss: 0.3038\n",
            "Epoch 3/3\n",
            "\u001b[1m1641/1641\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - acc: 0.9183 - loss: 0.2071 - val_acc: 0.8645 - val_loss: 0.3723\n",
            "\n",
            "Validation acc (best epoch): 0.875\n",
            "\n",
            "Test accuracy: 0.873   Test F1: 0.877\n",
            "\n",
            "Confusion matrix:\n",
            " [[3150  600]\n",
            " [ 354 3396]]\n",
            "\n",
            "Elapsed time: 00:03:02\n",
            "\n",
            "\n",
            "Creating new datasetset of size 1.0\n",
            "Pool after SUBSET_FRAC=1.0: 50000 (of 50000)\n",
            "Train: (35000, [17500, 17500])  Val: (5000, [2500, 2500])  Test: (10000, [5000, 5000])\n",
            "\n",
            "\n",
            "Running Bert model with data subset size 1.0\n",
            "Epoch 1/3\n",
            "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 37ms/step - acc: 0.8392 - loss: 0.3589 - val_acc: 0.8848 - val_loss: 0.2731\n",
            "Epoch 2/3\n",
            "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 18ms/step - acc: 0.8915 - loss: 0.2620 - val_acc: 0.8960 - val_loss: 0.2626\n",
            "Epoch 3/3\n",
            "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 17ms/step - acc: 0.9193 - loss: 0.2064 - val_acc: 0.8948 - val_loss: 0.2748\n",
            "\n",
            "Validation acc (best epoch): 0.896\n",
            "\n",
            "Test accuracy: 0.880   Test F1: 0.883\n",
            "\n",
            "Confusion matrix:\n",
            " [[4268  732]\n",
            " [ 471 4529]]\n",
            "\n",
            "Elapsed time: 00:03:38\n"
          ]
        }
      ],
      "source": [
        "# train the bert model with the best values from the previous problem\n",
        "best_max_len = 256\n",
        "best_lr = 7.5e-6\n",
        "best_batch = 16\n",
        "\n",
        "data_subset = [0.25, 0.50, 0.75, 1.00]\n",
        "\n",
        "for i, j in enumerate(data_subset):\n",
        "    print(f\"\\n\")\n",
        "    print(f\"Creating new datasetset of size {j}\")\n",
        "\n",
        "    # ---- Optional: take a stratified subset of the FULL dataset ----\n",
        "    if 0.0 < j < 1.0:\n",
        "        sub = all_ds.train_test_split(train_size=j, seed=SEED, stratify_by_column=\"label\")\n",
        "        ds_pool = sub[\"train\"]\n",
        "    else:\n",
        "        ds_pool = all_ds\n",
        "\n",
        "    # ---- Stratified 80/10/10 split on the (possibly smaller) pool ----\n",
        "    # First: 80/20 train+val pool / test\n",
        "    splits = ds_pool.train_test_split(test_size=0.20, seed=SEED, stratify_by_column=\"label\")\n",
        "    train_val_pool, test_ds = splits[\"train\"], splits[\"test\"]\n",
        "    # Then: carve 10% of full (i.e., 0.125 of the 80% pool) as validation\n",
        "    splits2 = train_val_pool.train_test_split(test_size=0.125, seed=SEED, stratify_by_column=\"label\")\n",
        "    train_ds, val_ds = splits2[\"train\"], splits2[\"test\"]\n",
        "\n",
        "    # ---- Numpy arrays for Keras fit/predict ----\n",
        "    X_tr = np.array(train_ds[\"text\"], dtype=object); y_tr = np.array(train_ds[\"label\"], dtype=\"int32\")\n",
        "    X_va = np.array(val_ds[\"text\"],   dtype=object); y_va = np.array(val_ds[\"label\"],   dtype=\"int32\")\n",
        "    X_te = np.array(test_ds[\"text\"],  dtype=object); y_te = np.array(test_ds[\"label\"],  dtype=\"int32\")\n",
        "\n",
        "    # ---- Quick summary ----\n",
        "\n",
        "    print(f\"Pool after SUBSET_FRAC={j}: {len(ds_pool)} (of {len(all_ds)})\")\n",
        "    print(\"Train:\", _counts(train_ds), \" Val:\", _counts(val_ds), \" Test:\", _counts(test_ds))\n",
        "    print(\"\\n\")\n",
        "    print(f\"Running Bert model with data subset size {j}\")\n",
        "\n",
        "    preproc = kh.models.DistilBertTextClassifierPreprocessor.from_preset(\n",
        "        \"distil_bert_base_en_uncased\", sequence_length=best_max_len\n",
        "    )\n",
        "    model = kh.models.DistilBertTextClassifier.from_preset(\n",
        "        \"distil_bert_base_en_uncased\", num_classes=2, preprocessor=preproc\n",
        "    )\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(best_lr),\n",
        "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
        "    )\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # ---- Train with early stopping (restore best val weights) ----\n",
        "    cb = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True)]\n",
        "    history = model.fit(\n",
        "        X_tr, y_tr,\n",
        "        validation_data=(X_va, y_va),\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=best_batch,\n",
        "        callbacks=cb,\n",
        "        verbose=1,\n",
        "    )\n",
        "\n",
        "    # ---- Evaluate (accuracy + F1 via `evaluate`) ----\n",
        "    logits = model.predict(X_te, batch_size=EVAL_BATCH, verbose=0)\n",
        "    y_pred = logits.argmax(axis=-1)\n",
        "\n",
        "    acc_metric = evaluate.load(\"accuracy\")\n",
        "    f1_metric  = evaluate.load(\"f1\")\n",
        "    acc = acc_metric.compute(predictions=y_pred, references=y_te)[\"accuracy\"]\n",
        "    f1  = f1_metric.compute(predictions=y_pred, references=y_te)[\"f1\"]\n",
        "\n",
        "    # ---- Print the evaluations ----\n",
        "    print(f\"\\nValidation acc (best epoch): {history.history['val_acc'][np.argmin(history.history['val_loss'])]:.3f}\")\n",
        "    print(f\"\\nTest accuracy: {acc:.3f}   Test F1: {f1:.3f}\")\n",
        "    print(\"\\nConfusion matrix:\\n\", confusion_matrix_np(y_te, y_pred))\n",
        "\n",
        "    end = time.time() - start\n",
        "    print(\"\\nElapsed time:\", time.strftime(\"%H:%M:%S\", time.gmtime(end)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43868b2d-3a63-4422-a11c-b0eb7ada89a7",
      "metadata": {
        "id": "43868b2d-3a63-4422-a11c-b0eb7ada89a7"
      },
      "source": [
        "### Graded Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "00abc6af-69f5-494e-8349-9e0ebf115e42",
      "metadata": {
        "id": "00abc6af-69f5-494e-8349-9e0ebf115e42"
      },
      "outputs": [],
      "source": [
        "# Set a2a to the validation accuracy at min validation loss for your best configuration found in this problem\n",
        "# (Yes, it is probably at 1.0!)\n",
        "\n",
        "a2a = 0.896           # Replace 0.0 with your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3a4afa0b-5e7d-4ba1-8bb5-8d5229aef4fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a4afa0b-5e7d-4ba1-8bb5-8d5229aef4fd",
        "outputId": "7d125558-273d-444b-d8be-a4f006a87103"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a2a = 0.8960\n"
          ]
        }
      ],
      "source": [
        "# Graded Answer\n",
        "# DO NOT change this cell in any way\n",
        "\n",
        "print(f'a2a = {a2a:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ba14dbe-08bd-4a03-ad90-2e2046a9ac78",
      "metadata": {
        "id": "5ba14dbe-08bd-4a03-ad90-2e2046a9ac78"
      },
      "source": [
        "#### Question a2b:\n",
        "\n",
        "Summarize what you observed as dataset size increased. Given that validation metrics are typically reliable to only about two decimal places, do the performance gains justify using the entire dataset? What trade-offs between accuracy and computation time did you notice?\n",
        "\n",
        "#### Your Answer Here: Given this datasets size, it's most beneficial to use the whole dataset as long as you have the proper hardware to run it. That is a big caveat for some so I can see the 50% dataset being just as valuable. As the dataset increased, the validation accuracy increased, about 2 percent each run, the time to run each model also increased proportinally by 30 sec for each run. Time wasn't much of a worry since the largest model took 3.5 min."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e8c9212-dde0-4a33-b926-70ef9dddd1be",
      "metadata": {
        "id": "1e8c9212-dde0-4a33-b926-70ef9dddd1be"
      },
      "source": [
        "# Problem 3 — Model swap: speed vs. accuracy (why: capacity matters)\n",
        "\n",
        "In this problem we will compare encoder-only backbones of different sizes.\n",
        "\n",
        "**Setup.** Keep the best `MAX_LEN`, `LR`, and `SUBSET_FRAC` from Problems 1–2. Only change the model/preset:\n",
        "\n",
        "* **DistilBERT** (current baseline)\n",
        "* **BERT-base** (larger/usually stronger)\n",
        "\n",
        "**How to switch (two lines each).**\n",
        "\n",
        "* DistilBERT:\n",
        "\n",
        "  ```python\n",
        "  preproc = kh.models.DistilBertTextClassifierPreprocessor.from_preset(\"distil_bert_base_en_uncased\", sequence_length=MAX_LEN)\n",
        "  model  = kh.models.DistilBertTextClassifier.from_preset(\"distil_bert_base_en_uncased\", num_classes=2, preprocessor=preproc)\n",
        "  ```\n",
        "\n",
        "* BERT-base:\n",
        "\n",
        "  ```python\n",
        "  preproc = kh.models.BertTextClassifierPreprocessor.from_preset(\"bert_base_en_uncased\", sequence_length=MAX_LEN)\n",
        "  model  = kh.models.BertTextClassifier.from_preset(\"bert_base_en_uncased\", num_classes=2, preprocessor=preproc)\n",
        "  ```\n",
        "\n",
        "**What to do.**\n",
        "\n",
        "1. Train/evaluate each model once with identical settings.\n",
        "2. Observe the performance metrics for each.\n",
        "3. Answer the graded questions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict = {\n",
        "    'DistilBert':\n",
        "      {\n",
        "          'Preprocessing': kh.models.DistilBertTextClassifierPreprocessor.from_preset(\"distil_bert_base_en_uncased\", sequence_length=MAX_LEN),\n",
        "          'Model':kh.models.DistilBertTextClassifier.from_preset(\"distil_bert_base_en_uncased\", num_classes=2, preprocessor=None) # Set preprocessor to None here\n",
        "      },\n",
        "    'Bert-base':\n",
        "      {\n",
        "          'Preprocessing': kh.models.BertTextClassifierPreprocessor.from_preset(\"bert_base_en_uncased\", sequence_length=MAX_LEN),\n",
        "          'Model': kh.models.BertTextClassifier.from_preset(\"bert_base_en_uncased\", num_classes=2, preprocessor=None) # Set preprocessor to None here\n",
        "      }\n",
        "  }\n",
        "\n",
        "for model_name, model_info in model_dict.items():\n",
        "  print(f\"Running {model_name} model ...\")\n",
        "\n",
        "  # Train/evaluate model\n",
        "  preproc = model_info['Preprocessing']\n",
        "  model = model_info['Model']\n",
        "\n",
        "  # Apply the preprocessor to the data\n",
        "  X_tr_processed = preproc(X_tr)\n",
        "  X_va_processed = preproc(X_va)\n",
        "  X_te_processed = preproc(X_te)\n",
        "\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=keras.optimizers.Adam(best_lr),\n",
        "      loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
        "  )\n",
        "\n",
        "  start = time.time()\n",
        "\n",
        "  # ---- Train with early stopping (restore best val weights) ----\n",
        "  cb = [keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=2, restore_best_weights=True)]\n",
        "  history = model.fit(\n",
        "      X_tr_processed, y_tr,\n",
        "      validation_data=(X_va_processed, y_va),\n",
        "      epochs=EPOCHS,\n",
        "      batch_size=best_batch,\n",
        "      callbacks=cb,\n",
        "      verbose=1,\n",
        "  )\n",
        "\n",
        "  # ---- Evaluate (accuracy + F1 via `evaluate`) ----\n",
        "  logits = model.predict(X_te_processed, batch_size=EVAL_BATCH, verbose=0)\n",
        "  y_pred = logits.argmax(axis=-1)\n",
        "\n",
        "  acc_metric = evaluate.load(\"accuracy\")\n",
        "  f1_metric  = evaluate.load(\"f1\")\n",
        "  acc = acc_metric.compute(predictions=y_pred, references=y_te)[\"accuracy\"]\n",
        "  f1  = f1_metric.compute(predictions=y_pred, references=y_te)[\"f1\"]\n",
        "\n",
        "  # ---- Print the evaluations ----\n",
        "  print(f\"\\nValidation acc (best epoch): {history.history['val_acc'][np.argmin(history.history['val_loss'])]:.3f}\")\n",
        "  print(f\"\\nTest accuracy: {acc:.3f}   Test F1: {f1:.3f}\")\n",
        "  print(\"\\nConfusion matrix:\\n\", confusion_matrix_np(y_te, y_pred))\n",
        "\n",
        "  end = time.time() - start\n",
        "  print(\"\\nElapsed time:\", time.strftime(\"%H:%M:%S\", time.gmtime(end)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q05Q11eilMmB",
        "outputId": "6b612080-7b1a-487a-b271-b8e9a8afa975"
      },
      "id": "Q05Q11eilMmB",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running DistilBert model ...\n",
            "Epoch 1/3\n",
            "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 32ms/step - acc: 0.8371 - loss: 0.3611 - val_acc: 0.8816 - val_loss: 0.2792\n",
            "Epoch 2/3\n",
            "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 17ms/step - acc: 0.8924 - loss: 0.2617 - val_acc: 0.8880 - val_loss: 0.2802\n",
            "Epoch 3/3\n",
            "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 17ms/step - acc: 0.9197 - loss: 0.2074 - val_acc: 0.8888 - val_loss: 0.2869\n",
            "\n",
            "Validation acc (best epoch): 0.882\n",
            "\n",
            "Test accuracy: 0.865   Test F1: 0.872\n",
            "\n",
            "Confusion matrix:\n",
            " [[4061  939]\n",
            " [ 411 4589]]\n",
            "\n",
            "Elapsed time: 00:03:22\n",
            "Running Bert-base model ...\n",
            "Epoch 1/3\n",
            "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 56ms/step - acc: 0.8506 - loss: 0.3346 - val_acc: 0.8944 - val_loss: 0.2519\n",
            "Epoch 2/3\n",
            "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 32ms/step - acc: 0.9104 - loss: 0.2224 - val_acc: 0.9004 - val_loss: 0.2465\n",
            "Epoch 3/3\n",
            "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 31ms/step - acc: 0.9463 - loss: 0.1465 - val_acc: 0.9008 - val_loss: 0.2625\n",
            "\n",
            "Validation acc (best epoch): 0.900\n",
            "\n",
            "Test accuracy: 0.894   Test F1: 0.896\n",
            "\n",
            "Confusion matrix:\n",
            " [[4357  643]\n",
            " [ 419 4581]]\n",
            "\n",
            "Elapsed time: 00:05:58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "147f3698-11a9-4451-a53e-a2e92e18421a",
      "metadata": {
        "id": "147f3698-11a9-4451-a53e-a2e92e18421a"
      },
      "source": [
        "### Graded Questions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "18d7925a-2494-4689-b329-0b625827a0a8",
      "metadata": {
        "id": "18d7925a-2494-4689-b329-0b625827a0a8"
      },
      "outputs": [],
      "source": [
        "# Set a1a to the validation accuracy at min validation loss for your best model found in this problem\n",
        "\n",
        "a3a = 0.900             # Replace 0.0 with your answer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "deec774a-2360-494d-9e2f-989164095a79",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deec774a-2360-494d-9e2f-989164095a79",
        "outputId": "96f5d1f0-e2af-43f1-8367-5f27bcc327c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a3a = 0.9000\n"
          ]
        }
      ],
      "source": [
        "# Graded Answer\n",
        "# DO NOT change this cell in any way\n",
        "\n",
        "print(f'a3a = {a3a:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "58b6ce4d-28a7-4414-8d1c-114a6bc5fa5f",
      "metadata": {
        "id": "58b6ce4d-28a7-4414-8d1c-114a6bc5fa5f"
      },
      "source": [
        "#### Question a3b:\n",
        "\n",
        "**Answer briefly.**\n",
        "\n",
        "* Which model gives the best **accuracy/F1**?\n",
        "* Which is **fastest** per epoch?\n",
        "* Given limited development time or compute resources, which model is the best **overall choice** and why?\n",
        "\n",
        "#### Your Answer Here:The best performing model was the last Bert-Base model which was testing on the whole dataset. The DistilBert model was the fastest per epoch. If limited development time and resources were an issue, the DistilBert model would be the best choice. It's evaluation performance in comparison within 1.5% and ran 30% faster than the Bert-base model. Cut down dataset versions of the DistilBert model also showed promise with accuracies in the mid-high 80's."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sq1Krfcezp6t"
      },
      "id": "Sq1Krfcezp6t",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "15dbe12a761e4e70a51e20770003fc1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0eabf0f7428f4a319d8ef84fdb4d8ca5",
              "IPY_MODEL_47b2f287487d48d295650dde5ae9861d",
              "IPY_MODEL_1bc00639181b4d23b0ef928094385bda"
            ],
            "layout": "IPY_MODEL_1b499c0665d543bb88ea7cb57fece253"
          }
        },
        "0eabf0f7428f4a319d8ef84fdb4d8ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dca0b379100741dc846e017a5d614c76",
            "placeholder": "​",
            "style": "IPY_MODEL_74c3219ccdd94e0ab1713f6e3ff301ff",
            "value": "Downloading builder script: "
          }
        },
        "47b2f287487d48d295650dde5ae9861d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ea50da1c49647a8a06ce8232d0521e7",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bd65acdaa6064ee8a6f27ad2d57f9ef1",
            "value": 1
          }
        },
        "1bc00639181b4d23b0ef928094385bda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4926984e46164c0d83ed2e3a0caffc47",
            "placeholder": "​",
            "style": "IPY_MODEL_aae4943ef9e54eabbc6c0d6d7cc39831",
            "value": " 4.20k/? [00:00&lt;00:00, 443kB/s]"
          }
        },
        "1b499c0665d543bb88ea7cb57fece253": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dca0b379100741dc846e017a5d614c76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74c3219ccdd94e0ab1713f6e3ff301ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ea50da1c49647a8a06ce8232d0521e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "bd65acdaa6064ee8a6f27ad2d57f9ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4926984e46164c0d83ed2e3a0caffc47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aae4943ef9e54eabbc6c0d6d7cc39831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0283cc0c54c4225ab06448e789db75d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34d7059fe01a4a92a3d54b601ba897c3",
              "IPY_MODEL_40e31ae2250a4e388285b59d229489dd",
              "IPY_MODEL_bd8c60b8d74848bebe39458acb5e37ca"
            ],
            "layout": "IPY_MODEL_49aaf1aa3e384c38b239fdd6f50ae46e"
          }
        },
        "34d7059fe01a4a92a3d54b601ba897c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d50d1e7173c49fa8c7a4e0db08a42e4",
            "placeholder": "​",
            "style": "IPY_MODEL_275a90afc6064a4dadedd928e9663749",
            "value": "Downloading builder script: "
          }
        },
        "40e31ae2250a4e388285b59d229489dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c250c46f87e44f4cb265da7edc38d42c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9d56cb52532a4c318b63e6657c66fd9c",
            "value": 1
          }
        },
        "bd8c60b8d74848bebe39458acb5e37ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9f963be16574379aa7d828635b5a66b",
            "placeholder": "​",
            "style": "IPY_MODEL_a98d4e503d254967b96a4c8bbb7cba5b",
            "value": " 6.79k/? [00:00&lt;00:00, 766kB/s]"
          }
        },
        "49aaf1aa3e384c38b239fdd6f50ae46e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d50d1e7173c49fa8c7a4e0db08a42e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "275a90afc6064a4dadedd928e9663749": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c250c46f87e44f4cb265da7edc38d42c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "9d56cb52532a4c318b63e6657c66fd9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c9f963be16574379aa7d828635b5a66b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a98d4e503d254967b96a4c8bbb7cba5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}